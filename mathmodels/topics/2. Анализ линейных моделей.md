Анализируем линейные динамические модели с постоянной матрицей
$$\frac{d\mathbf{x}}{dt}=\mathbf{Ax}+\mathbf{b}$$
# Основные этапы
1. Получение решения (динамического) + получение стационарного решения и анализ его устойчивости
2. Оценка наблюдаемости и роли отдельных составляющих решения
3. Оценка чувствительности к параметрам
4. Решение задачи параметрической идентификации
5. Решение задач управления (выбора оптимальных значений параметров)
# 1а. Получение стационарного решения
Решаем $\mathbf{Ax}+\mathbf{b}=0$; $\mathbf{x}^*=-\mathbf{A}^{-1}\mathbf{b}$. Например, с помощью ***DECOMP*** и ***SOLVE***.
Анализ устойчивости выполняется на основе ***QR***-алгоритма ($Re\lambda_k < 0$ для асимптотической устойчивости).
# 1. Получение динамического решения
Можно воспользоваться ***RKF45***, но эффективнее учитывать линейные свойства. Точное решение:
$$\mathbf{x}(t)=e^{\mA t}\mathbf{x}_0+\int_{0}^{t}e^{\mathbf{A}\tau}d\tau \times \mathbf{b}$$
Запишем его в точке $t_{n+1}=t_n+H$ и вычтем $e^{\mathbf{A}H}\mathbf{x}(t_n)$, $H$ — шаг наблюдения решения. Первое слагаемое сокращается.
$$\mathbf{x}(t_n+H)-e^{\mathbf{A}H}\mathbf{x}(t_n)=\left(\int_0^{t_n+H}e^{\mathbf{A}\tau}d\tau-e^{\mathbf{A}H}\int_0^{t_n}e^{\mathbf{A}\tau}d\tau\right)\times\mathbf{b}$$
Переносим слагаемое в правую часть и вносим $e^{\mathbf{A}H}$ под интеграл.
$$\mathbf{x}(t_n+H)=e^{\mathbf{A}H}\mathbf{x}(t_n)+\left(\int_0^{t_n+H}e^{\mathbf{A}\tau}d\tau-\int_H^{t_n+H}e^{\mathbf{A}\tau}d\tau\right)\times\mathbf{b}$$
Вычитаем интегралы.
$$\mathbf{x}(t_n+H)=e^{\mathbf{A}H}\mathbf{x}(t_n)+\int_0^{H}e^{\mathbf{A}\tau}d\tau\times\mathbf{b}$$
Эта формула позволяет *однократно* посчитать матричную экспоненту и интеграл, так как они не зависят от $t$, а затем использовать пошаговый метод.
## Вычисление матричной экспоненты
Для вычисления матричной экспоненты и интеграла воспользуемся матричным степенным разложением.
$$\displaylines{e^{\mA H}\approx
\mathbf{E}+H\mA+\frac{H^2\mA^2}{2}+\dots \\
\int_0^He^{\mA\tau}d\tau\approx 
H\left(\mathbf{E}+\frac{H\mA}{2}+\frac{H^2\mA^2}{6}+\dots\right)}$$
Для удовлетворительной скорости сходимости необходимо обеспечить выполнение $\left|\lambda_k\right|_{max}H<1$ или $||\mA||H<1$.

Если невозможно обеспечить выполнение этого условия (система жёсткая), то по желаемому значению $H$ выбирается такое целое $N$, что для $h=\frac{H}{2^N}$ это условие выполняется. Далее строится $e^{\mathbf{A}h}$ и $N$ раз возводится в квадрат, достигая матрицы $e^{\mathbf{A}H}$.

Аналогичная формула для вектора (второго слагаемого)
$$\mathbf{g}(h)=
\int_0^he^{\mA\tau}d\tau\times\mB \quad 
\mathbf{g}(2h)=
\left(\mathbf{E}+e^{\mA h}\right)\mathbf{g}(h)$$
Для доказательства делим интеграл на две части и делаем замену переменной во втором.
$$\begin{align}
\mathbf{g}(2h)=&
\int_0^{2h}e^{\mA\tau}d\tau\times\mB=\\
=&\int_0^he^{\mA\tau}d\tau\times\mB+
\int_h^{2h}e^{\mA\tau}d\tau\times\mB=\\
=&\int_0^he^{\mA\tau}d\tau\times\mB+
e^{\mA h}\int_0^he^{\mA\tau}d\tau\times\mB=\\
=&(\mathbf{E}+e^{\mA h})\mathbf{g}(h)
\end{align}$$
## Алгоритм
1. Задаём желаемое $H$. Выбираем $N$ так, что
$$h=\frac{H}{2^N}<\frac1{||\mA||}$$
2. Для $h$ строим матричную экспоненту $e^{\mA h}$ и вектор $\mathbf{g}(h)$
3. Используем формулы удвоения шага и получаем $e^{\mA H}$ и $\mathbf{g}(H)$
4. Решаем уравнение пошаговым методом
## Программа LSODE
Этот алгоритм реализован в программе 
***LSODE(N, H, CH, A, B, X, EAH, SL, INDEX)***, где
***N*** — размерность системы,
***H*** — желаемый шаг,
***CH*** — для оценки шага $h$ (0.1..5.0),
***A, B*** — матрица и вектор системы,
***X*** — вектор решения,
***EAH*** — $e^{\mA H}$,
***SL*** — рабочий массив,
***INDEX*** — управляющий параметр.

Если игнорировать ошибки округления, то все вычисления, кроме разложения, точные. Разложить можно до ошибки округления.
# 2. Определение наблюдаемости отдельных составляющих решения
## Формула Лагранжа-Сильвестра
Пусть
$$\begin{align}
\mA \mathbf{u}_k&=\lambda_k\mathbf{u}_k \\
\mA^T\mathbf{v}_i&=\lambda_i\mathbf{v}_i
\end{align}
$$
Транспонируем последнюю формулу.
$$\mathbf{v}_i^T\mA=\lambda_i\mathbf{v}_i^T$$
Первую формулу умножаем слева на $\mathbf{v}_i^T$, а третью справа на $\mathbf{u}_k$, вычитаем.
$$0=(\lambda_k-\lambda_i)\mathbf{v}_i^T\mathbf{u}_k$$
Если $k\neq i$, то
$$\mathbf{v}_i^T\mathbf{u}_k=0$$
Дополнительно нормируем эти векторы так, что
$$\mathbf{v}_k^T\mathbf{u}_k=1$$
Формула Лагранжа-Сильвестра
$$\displaylines{
\mathbf{f}(\mathbf{A})=\sum_{k=1}^{m}\mathbf{T}_kf(\lambda_k)\\
\mathbf{T}_k=\frac
{
(\mA-\lambda_1\mE)\dots(\mA-\lambda_{k-1}\mE)
(\mA-\lambda_{k+1}\mE)\dots(\mA-\lambda_{m}\mE)
}
{
(\lambda_k-\lambda_1)\dots(\lambda_k-\lambda_{k-1})
(\lambda_k-\lambda_{k+1})\dots(\lambda_k-\lambda_{m})
}
}$$
Для чужих собственных векторов $i\neq k$ (так как $(\mA-\lambda_i\mE)\times \mathbf{u}_i=\mathbf{0}$)
$$\mathbf{T}_k\mathbf{u}_i=0$$
Для своих собственных векторов (умножить все множители на $\mathbf{u}_k$)
$$\mathbf{T}_k\mathbf{u}_k=\mathbf{u}_k$$
Разложим каждую строку
$$\mathbf{T}_k=\sum_{j=1}^m\mathbf{c}_j\mathbf{v}_j^T$$
Если $k\neq i$ 
$$\mathbf{T}_k\mathbf{u}_i=
\sum_{j=1}^m(\mathbf{c}_j\mathbf{v}_j^T) \mathbf{u}_i=
\sum_{j=1}^m\mathbf{c}_j(\mathbf{v}_j^T \mathbf{u}_i)=
\mathbf{c}_i(\mathbf{v}_i^T \mathbf{u}_i)=\mathbf{c}_i=\mathbf{0}$$
То есть
$$\mathbf{T}_k=\mathbf{c}_k\mathbf{v}_k^T$$
Подставляем это в выражение со своими собственными векторами
$$(\mathbf{c}_k\mathbf{v}_k^T)\mathbf{u}_k=
\mathbf{c}_k(\mathbf{v}_k^T\mathbf{u}_k)=
\mathbf{c}_k=\mathbf{u}_k$$
Теперь формулу Лагранжа-Сильвестра можно записать так
$$\mathbf{f}(\mA)=\sum_{k=1}^m \mathbf{u}_k\mathbf{v}_k^Tf(\lambda_k)$$
## Наблюдаемость отдельных составляющих
Запишем решение через матричную экспоненту по формуле Лагранжа-Сильвестра, когда $\mB=\mathbf{0}$.
$$\mx(t)=e^{\mA t}\mx_0=\sum_{k=1}^m\mu_k\mv_k^T e^{\lambda_k t}\mx_0=\sum_{k=1}^m\mu_k(\mv_k^T \mx_0)e^{\lambda_k t}$$
Составляющая $e^{\lambda_k t}$ называется ***модой***, анализ — ***модальным анализом***.
Пусть
$$D_k=\mv_k^T\mx_0$$
Покомпонентно запишем решение.
$$\begin{align}
x^{(1)}(t)&=u_1^{(1)}D_1e^{\lambda_1 t}+
u_2^{(1)}D_2e^{\lambda_2 t}+\dots+
u_m^{(1)}D_me^{\lambda_m t}\\
x^{(2)}(t)&=u_1^{(2)}D_1e^{\lambda_1 t}+
u_2^{(2)}D_2e^{\lambda_2 t}+\dots+
u_m^{(2)}D_me^{\lambda_m t}\\
\vdots\\
x^{(m)}(t)&=u_1^{(m)}D_1e^{\lambda_1 t}+
u_2^{(m)}D_2e^{\lambda_2 t}+\dots+
u_m^{(m)}D_me^{\lambda_m t}
\end{align}$$
> [!вопрос] 
> Насколько заметнее $k$-я мода $e^{\lambda_k t}$ наблюдается в $x^{(p)}(t)$ по сравнению с $x^{(s)}(t)$?

Отношение амплитуд выражается частным
$$\eta_k^{(p,s)}=\frac{u_k^{(p)}D_k}{u_k^{(s)}D_k}=\frac{u_k^{(p)}}{u_k^{(s)}}$$
Оно **не зависит от начальных условий** $\mx_0$ и полностью определяется компонентами собственного вектора $\mu_k$.

Введём упрощающие предположения. Каждый узел описывается дифференциальным уравнением. Все они имеют одинаковую природу и размерность.
$$\frac{dx^{(p)}}{dt}=\dots$$
Возмущения будем задавать вектором начальных условий, где одна компонента равна единице, остальные нули.
$$\mx_0=\mathbf{e}_i=(0,0,\dots,0,1,0,\dots,0,0)^T$$
## Подсистема 1. Оценка поведения $k$-й моды $e^{\lambda_k t}$
Выбираем наибольшую по модулю компоненту $u_k$ и делим другие на неё, получаем относительную амплитуду.

***Наблюдаемость $k$-й моды***

| Номер узла | Относительная амплитуда |
|------------|-------------------------|
| 14         | 100%                    |
| 3          | 92%                     |
| 115        | 14%                     |
| 7          | 0.2%                    |
| ...        | ...                     |

Мода ***локальная***, если она заметно наблюдается в небольшом числе узлов. Иначе она называется ***системной***.

Величина $D_k=\mv_k^T\mx_0$ достигает максимума, если ненулевую компоненту $\mx_0$ задать там, где компонента $\mv_k$ наибольшая по модулю.

***Возмущаемость $k$-й моды***

| Номер узла | Относительная амплитуда |
|------------|-------------------------|
| 14         | 100%                    |
| 6          | 78%                     |
| 217        | 9%                      |
| 29         | 0.05%                   |
| ...        | ...                     |

## Подсистема 2. Наблюдение в данном узле
Интерес вызывает только одна составляющая решения
$$x^{(k)}(t)=u_1^{(k)}D_1e^{\lambda_1 t}+
u_2^{(k)}D_2e^{\lambda_2 t}+\dots+
u_m^{(k)}D_me^{\lambda_m t}$$
Задача — указать, какая мода будет иметь максимальную амплитуду, и упорядочить моды по убыванию этих амплитуд. Для каждой моды указан узел, где возмущение наиболее эффективно.

| Номер моды | Относительная амплитуда | Эффективный узел возмущения |
|------------|-------------------------|-----------------------------|
| 4          | 65%                     | 7                           |
| 13         | 15%                     | 14                          |
| 6          | 14%                     | 113                         |
| 25         | 3%                      | 3                           |
| ...        | ...                     | ...                         |

## Подсистема 3. Возмущение в данном узле
Интерес вызывают последствия возмущения в данном узле. Таким образом, $\mx_0$ и $D_j$ известны.

| Номер моды | Относительная амплитуда | Эффективный узел наблюдения |
|------------|-------------------------|-----------------------------|
| 4          | 65%                     | 7                           |
| 13         | 15%                     | 14                          |
| 6          | 14%                     | 113                         |
| 25         | 3%                      | 3                           |
| ...        | ...                     | ...                         |

# 3. Оценка чувствительности к параметрам
Рассмотри статическую модель
$$\mathbf{f(x(k))}=0$$
где $\mx$ — вектор из $m$ выходных переменных, а $\mathbf{k}$ — вектор из $s$ параметров. В первом приближении влияние параметров можно выразить в прямоугольной матрице $m\times s$ с элементами
$$a_{ij}=\frac{\partial x^{(i)}}{\partial k^{(j)}}$$
Они могут быть оценены по формулам численного дифференцирования. Например,
$$\mA_j\approx \frac{\mx(\mathbf{k}+\Delta k\times\mathbf{e}_j)-\mx(\mathbf{k})}{\Delta k}$$
Рассмотрим динамическую модель
$$\frac{d\mx}{dt}=\mA(k)\mx$$
Чувствительность решения определяется чувствительностью собственных значений.
$$\mA(k)\mu_i=\lambda_i\mu_i$$
Дифференцируем по $k$
$$\frac{\partial\mA}{\partial k}\mu_i+\mA\frac{\partial \mu_i}{\partial k}=\frac{\partial \lambda_i}{\partial k}\mu_i+\lambda_i\frac{\partial \mu_i}{\partial k}$$
Умножаем слева на $\mv_i^T$ и переносим последнее слагаемое в левую часть
$$\mv_i^T\frac{\partial \mA}{\partial k}\mu_i+\left(\mv_i^T\mA-\lambda_i\mv_i^T\right)\frac{\partial \mu_i}{\partial k}=\mv_i^T\frac{\partial \lambda_i}{\partial k}\mu_i$$
Скобка равна нулю. Выразим
$$\frac{\partial \lambda_i}{\partial k}=\frac{\mv_i^T\frac{\partial \mA}{\partial k}\mu_i}{\mv_i^T\mu_i}$$
Если векторы нормированы, то
$$\frac{\partial \lambda_i}{\partial k}=\mv_i^T\frac{\partial \mA}{\partial k}\mu_i$$
> [!пример]
> Выберем элемент матрицы в качестве $k=a_{ps}$.
> Тогда матрица $\frac{\partial\mA}{\partial k}$ имеет единственный ненулевой элемент — $1$ на пересечении $p$-й строки и $s$-го столбца.
> $$\frac{\partial \lambda_i}{\partial a_{ps}}=v_i^{(p)}u_i^{(s)}$$
> Если значение получилось равно нулю, то **в первом приближении** влияние не оказывается, надо смотреть следующие производные.

# 4. Решение задачи параметрической идентификации
Рассмотрим
$$\frac{d\mx}{dt}=\mathbf{f}(t,\mx,\mathbf{p}), \mx(t_0)=\mx_0$$
Необходимо подобрать $\mathbf{p}$ так, чтобы модель максимально соответствовала экспериментальным данным.

Критерий близости
$$F(\mathbf{p})=\sum_k\sum_{i=1}^N\left(
x_{эксп}^{(k)}(t_i)-x^{(k)}(t_i)
\right)^2$$
Может быть использован любой метод минимизации.
# 5. Решение задач управления или выбора оптимальных значений параметров
$$\frac{d\mx}{dt}=\mA(\mathbf{k})\mx$$
Вектор параметров $\mathbf{k}$ нужно выбрать так, чтобы обеспечить желаемое смещение влево собственных значений.
Разложим в ряд
$$\alpha_j(\mathbf{k}_0+\Delta \mathbf{k})=
\alpha_j(\mathbf{k}_0)+
\frac{\partial\alpha_j}{\partial k^{(1)}}\Delta k^{(1)}+
\frac{\partial\alpha_j}{\partial k^{(2)}}\Delta k^{(2)}+
\dots+
\frac{\partial\alpha_j}{\partial k^{(s)}}\Delta k^{(s)}$$
Перенесём $\alpha_j(\mathbf{k}_0)$ влево и перепишем в матричной форме
$$\mathbf{\Phi}\Delta\mathbf{k}=\Delta\mathbf{\alpha}$$
Элементы матрицы $\mathbf{\Phi}$ вычисляются по формуле
$$f_{jp}=\frac{\partial\alpha_j}{\partial k^{(p)}}=
Re\left(\frac{\partial\lambda_j}{\partial k^{(p)}}\right)=
Re\left(\frac{\mv_j^T\frac{\partial \mA}{\partial k^{(p)}}\mu_j}{\mv_j^T\mu^j}\right)$$
Так как эта система с прямоугольной матрицей, в качестве решения принимается вектор $\Delta \mathbf{k}$, который минимизирует вектор невязки
$$\mathbf{r}=\mathbf{\Phi}\Delta\mathbf{k}-\Delta\mathbf{\alpha}$$
Для решения может быть использована программа ***SVD***.